{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFor...f',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.872\n",
      "SVC 0.888\n",
      "VotingClassifier 0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/share64/debian7/anaconda/anaconda3-5.1/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFor...bf',\n",
       "  max_iter=-1, probability=True, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.872\n",
      "SVC 0.888\n",
      "VotingClassifier 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/share64/debian7/anaconda/anaconda3-5.1/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16, random_state=42),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred == y_pred_rf) / len(y_pred)  # almost identical predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.11249225099876374\n",
      "sepal width (cm) 0.023119288282510326\n",
      "petal length (cm) 0.44103046436395765\n",
      "petal width (cm) 0.4233579963547681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Bag evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True, random_state=40)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31746032, 0.68253968],\n",
       "       [0.34117647, 0.65882353],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08379888, 0.91620112],\n",
       "       [0.31693989, 0.68306011],\n",
       "       [0.02923977, 0.97076023],\n",
       "       [0.97687861, 0.02312139],\n",
       "       [0.97765363, 0.02234637],\n",
       "       [0.74404762, 0.25595238],\n",
       "       [0.        , 1.        ],\n",
       "       [0.71195652, 0.28804348],\n",
       "       [0.83957219, 0.16042781],\n",
       "       [0.97777778, 0.02222222],\n",
       "       [0.0625    , 0.9375    ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97297297, 0.02702703],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01704545, 0.98295455],\n",
       "       [0.38947368, 0.61052632],\n",
       "       [0.88700565, 0.11299435],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96685083, 0.03314917],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64804469, 0.35195531],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.13402062, 0.86597938],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.36065574, 0.63934426],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.27093596, 0.72906404],\n",
       "       [0.34146341, 0.65853659],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.98265896, 0.01734104],\n",
       "       [0.91428571, 0.08571429],\n",
       "       [0.97282609, 0.02717391],\n",
       "       [0.97029703, 0.02970297],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06134969, 0.93865031],\n",
       "       [0.98019802, 0.01980198],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97790055, 0.02209945],\n",
       "       [0.79473684, 0.20526316],\n",
       "       [0.41919192, 0.58080808],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.        , 1.        ],\n",
       "       [0.67613636, 0.32386364],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87356322, 0.12643678],\n",
       "       [1.        , 0.        ],\n",
       "       [0.56140351, 0.43859649],\n",
       "       [0.16304348, 0.83695652],\n",
       "       [0.67539267, 0.32460733],\n",
       "       [0.90673575, 0.09326425],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16201117, 0.83798883],\n",
       "       [0.89005236, 0.10994764],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.995     , 0.005     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07272727, 0.92727273],\n",
       "       [0.05418719, 0.94581281],\n",
       "       [0.29533679, 0.70466321],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.81871345, 0.18128655],\n",
       "       [0.01092896, 0.98907104],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.22513089, 0.77486911],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9368932 , 0.0631068 ],\n",
       "       [0.76536313, 0.23463687],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.17127072, 0.82872928],\n",
       "       [0.65306122, 0.34693878],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03076923, 0.96923077],\n",
       "       [0.49444444, 0.50555556],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02673797, 0.97326203],\n",
       "       [0.98870056, 0.01129944],\n",
       "       [0.23121387, 0.76878613],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [0.98963731, 0.01036269],\n",
       "       [0.25641026, 0.74358974],\n",
       "       [0.92972973, 0.07027027],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.80681818, 0.19318182],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0106383 , 0.9893617 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01036269, 0.98963731],\n",
       "       [0.97752809, 0.02247191],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.01960784, 0.98039216],\n",
       "       [0.18367347, 0.81632653],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [0.29533679, 0.70466321],\n",
       "       [0.98295455, 0.01704545],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [0.75138122, 0.24861878],\n",
       "       [0.38624339, 0.61375661],\n",
       "       [0.42708333, 0.57291667],\n",
       "       [0.86315789, 0.13684211],\n",
       "       [0.92964824, 0.07035176],\n",
       "       [0.05699482, 0.94300518],\n",
       "       [0.82802548, 0.17197452],\n",
       "       [0.01546392, 0.98453608],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02298851, 0.97701149],\n",
       "       [0.96721311, 0.03278689],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01041667, 0.98958333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0326087 , 0.9673913 ],\n",
       "       [0.01020408, 0.98979592],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93785311, 0.06214689],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.        , 1.        ],\n",
       "       [0.38860104, 0.61139896],\n",
       "       [0.32065217, 0.67934783],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.31182796, 0.68817204],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00588235, 0.99411765],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62264151, 0.37735849],\n",
       "       [0.92344498, 0.07655502],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99526066, 0.00473934],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98888889, 0.01111111],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.06451613, 0.93548387],\n",
       "       [1.        , 0.        ],\n",
       "       [0.05154639, 0.94845361],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03278689, 0.96721311],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95808383, 0.04191617],\n",
       "       [0.79532164, 0.20467836],\n",
       "       [0.55665025, 0.44334975],\n",
       "       [0.        , 1.        ],\n",
       "       [0.18604651, 0.81395349],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93121693, 0.06878307],\n",
       "       [0.97740113, 0.02259887],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.        , 1.        ],\n",
       "       [0.44623656, 0.55376344],\n",
       "       [0.86363636, 0.13636364],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96923077, 0.03076923],\n",
       "       [0.        , 1.        ],\n",
       "       [0.21649485, 0.78350515],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98477157, 0.01522843],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.99441341, 0.00558659],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08379888, 0.91620112],\n",
       "       [0.98984772, 0.01015228],\n",
       "       [0.01142857, 0.98857143],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02747253, 0.97252747],\n",
       "       [1.        , 0.        ],\n",
       "       [0.79144385, 0.20855615],\n",
       "       [0.        , 1.        ],\n",
       "       [0.90804598, 0.09195402],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [0.20634921, 0.79365079],\n",
       "       [0.19767442, 0.80232558],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.20338983, 0.79661017],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98969072, 0.01030928],\n",
       "       [0.        , 1.        ],\n",
       "       [0.48663102, 0.51336898],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07821229, 0.92178771],\n",
       "       [0.11176471, 0.88823529],\n",
       "       [0.99415205, 0.00584795],\n",
       "       [0.03015075, 0.96984925],\n",
       "       [1.        , 0.        ],\n",
       "       [0.40837696, 0.59162304],\n",
       "       [0.04891304, 0.95108696],\n",
       "       [0.51595745, 0.48404255],\n",
       "       [0.51898734, 0.48101266],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.59903382, 0.40096618],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.24157303, 0.75842697],\n",
       "       [0.81052632, 0.18947368],\n",
       "       [0.08717949, 0.91282051],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.82142857, 0.17857143],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.125     , 0.875     ],\n",
       "       [0.04712042, 0.95287958],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.89150943, 0.10849057],\n",
       "       [0.1978022 , 0.8021978 ],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [0.00515464, 0.99484536],\n",
       "       [0.609375  , 0.390625  ],\n",
       "       [0.07692308, 0.92307692],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.84210526, 0.15789474],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.95876289, 0.04123711],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.26903553, 0.73096447],\n",
       "       [0.98461538, 0.01538462],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00574713, 0.99425287],\n",
       "       [0.85142857, 0.14857143],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76506024, 0.23493976],\n",
       "       [0.8969697 , 0.1030303 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.47727273, 0.52272727],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92473118, 0.07526882],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87709497, 0.12290503],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.74752475, 0.25247525],\n",
       "       [0.09146341, 0.90853659],\n",
       "       [0.44329897, 0.55670103],\n",
       "       [0.22395833, 0.77604167],\n",
       "       [0.        , 1.        ],\n",
       "       [0.87046632, 0.12953368],\n",
       "       [0.78212291, 0.21787709],\n",
       "       [0.00507614, 0.99492386],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02884615, 0.97115385],\n",
       "       [0.96571429, 0.03428571],\n",
       "       [0.93478261, 0.06521739],\n",
       "       [1.        , 0.        ],\n",
       "       [0.49756098, 0.50243902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01604278, 0.98395722],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96987952, 0.03012048],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05747126, 0.94252874],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98989899, 0.01010101],\n",
       "       [0.01675978, 0.98324022],\n",
       "       [1.        , 0.        ],\n",
       "       [0.13541667, 0.86458333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [0.        , 1.        ],\n",
       "       [0.41836735, 0.58163265],\n",
       "       [0.11309524, 0.88690476],\n",
       "       [0.22110553, 0.77889447],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97647059, 0.02352941],\n",
       "       [0.22826087, 0.77173913],\n",
       "       [0.98882682, 0.01117318],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96428571, 0.03571429],\n",
       "       [0.33507853, 0.66492147],\n",
       "       [0.98235294, 0.01764706],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06043956, 0.93956044],\n",
       "       [0.97619048, 0.02380952],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03108808, 0.96891192],\n",
       "       [0.57291667, 0.42708333]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {
   "height": "252px",
   "width": "333px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
